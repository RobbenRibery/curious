export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128,expandable_segments:True"
python training.py \
    --wandb_config.name "grpo-ietrate-prompt[deepseek]-reward[no-format]-kl[0.0]-max_gen[1400]" \
    --base_config.checkpoint_interval 50 \
    --base_config.mode "train" \
    --base_config.dataset_name "openai/gsm8k" \
    --base_config.model_name "Qwen/Qwen2-0.5B-Instruct" \
    --base_config.device_index 0 \
    --base_config.num_workers 8 \
    --base_config.seed 42 \
    --base_config.log_dir "train_logs" \
    --base_config.batch_size 8 \
    --grpo_config.mini_batch_size 16 \
    --grpo_config.epochs_per_step 2 \
    --grpo_config.group_size 16 \
    --grpo_config.lr 1e-06 \
    --grpo_config.kl_weight 0.0 \
    --grpo_config.clip_eps 0.2 \
    --sampling_config.max_new_tokens 1400 \
    --sampling_config.top_p 1.0 \
    --sampling_config.repetition_penalty 1.1 \
    --sampling_config.system_prompt "deepseek_system_prompt" \
    --reward_config.no-use-format-reward \