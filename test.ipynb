{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-11 09:47:53,585] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/conda/miniconda3/envs/cloudspace/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/system/conda/miniconda3/envs/cloudspace/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/system/conda/miniconda3/envs/cloudspace/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/system/conda/miniconda3/envs/cloudspace/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/system/conda/miniconda3/envs/cloudspace/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "import torch  \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from curious.utils.utils import move_paddings_to_right\n",
    "from curious.config import TrainingConfig, RLConfig, WandbConfig, BaseConfig, SamplingConfig, RewardConfig, SFLConfig \n",
    "from curious.train.training_setup import set_up_training\n",
    "from curious.train.trainer import PolicyGradientTrainer\n",
    "from curious.sampling.sampling import sequences_log_probs \n",
    "from curious.policy_gradient.loss import ActorLoss\n",
    "from curious.replay.experience import Experience, ReplayBuffer, join_experience_batch\n",
    "\n",
    "PAD_TOKEN_ID = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1,   2,   3, 890, 891, 128, 128],\n",
       "         [  1,   2,   3,   4, 899, 900, 911]]),\n",
       " tensor([[False, False,  True,  True, False, False],\n",
       "         [False, False, False,  True,  True,  True]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 1, 1, 1],\n",
    "        [0, 1, 1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_ids = torch.tensor(\n",
    "    [\n",
    "        [PAD_TOKEN_ID, PAD_TOKEN_ID, 1, 2, 3,],\n",
    "        [PAD_TOKEN_ID, 1,            2, 3, 4,],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sequence_ids = torch.tensor(\n",
    "    [\n",
    "        [PAD_TOKEN_ID, PAD_TOKEN_ID, 1, 2, 3, 890, 891, PAD_TOKEN_ID, PAD_TOKEN_ID, PAD_TOKEN_ID],\n",
    "        [PAD_TOKEN_ID, 1,            2, 3, 4, 899, 900, 911,          PAD_TOKEN_ID, PAD_TOKEN_ID],\n",
    "    ]\n",
    ")\n",
    "\n",
    "move_paddings_to_right(input_ids, attention_mask, sequence_ids, PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Loading target policy Qwen/Qwen2-0.5B-Instruct ####\n",
      "Applied Liger kernels to Qwen2\n",
      "#### Loading dataset openai/gsm8k ####\n",
      "Detected train_max_length: 212\n",
      "Setting train_max_length to 212\n",
      "Detected test_max_length: 188\n",
      "Setting test_max_length to 188\n",
      "#### Loading rollout data loader ####\n",
      "#### Defining actor loss ####\n",
      "#### Defining reward model ####\n",
      "#### Defining generation config ####\n",
      "#### Defining evaluation config ####\n",
      "#### Defining optimizer ####\n",
      "#### Defining lr scheduler ####\n"
     ]
    }
   ],
   "source": [
    "train_config = TrainingConfig(\n",
    "    rl_config=RLConfig(\n",
    "        group_size=3, \n",
    "        mini_batch_size=6,\n",
    "        kl_weight=0,\n",
    "        \n",
    "    ),\n",
    "    wandb_config=WandbConfig(),\n",
    "    base_config=BaseConfig(\n",
    "        train_batch_size=2,\n",
    "        \n",
    "    ),\n",
    "    sampling_config=SamplingConfig(\n",
    "        max_new_tokens=256,\n",
    "    ),\n",
    "    reward_config=RewardConfig(),\n",
    "    sfl_config=SFLConfig(\n",
    "    ),\n",
    ")\n",
    "#train_config.rl_config\n",
    "training_setup, init_train_state = set_up_training(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['run_name', 'device', 'seed', 'model', 'optimizer', 'lr_scheduler', 'reference_model', 'kl_controller'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_train_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PolicyGradientTrainer(training_setup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs = next(iter(trainer.rollout_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] Graph break from `Tensor.item()`, consider setting:\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] or:\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] to include these operations in the captured graph.\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] \n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] Graph break: from user code at:\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     return func(*args, **kwargs)\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/liger_kernel/transformers/model/qwen2.py\", line 188, in lce_forward\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     outputs = self.model(\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     output = func(self, *args, **kwargs)\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 519, in forward\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     causal_mask = self._update_causal_mask(\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 589, in _update_causal_mask\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0]     is_padding_right = attention_mask[:, -1].sum().item() != input_tensor.size()[0]\n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] \n",
      "W0511 09:48:09.775000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [0/0] \n",
      "W0511 09:49:06.208000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:906] [9/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W0511 09:49:06.208000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    function: 'forward' (/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:152)\n",
      "W0511 09:49:06.208000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    last reason: 9/0: not L['past_key_value'].key_cache                           \n",
      "W0511 09:49:06.208000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0511 09:49:06.208000 47207 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:679: UserWarning: Graph break due to unsupported builtin gc.collect. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.\n",
      "  torch._dynamo.utils.warn_once(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Batch indx <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Batch indx \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.memory_allocated: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>928201GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.memory_allocated: \u001b[1;36m0.\u001b[0m928201GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.memory_reserved: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>644531GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.memory_reserved: \u001b[1;36m1.\u001b[0m644531GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.max_memory_reserved: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>681641GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.max_memory_reserved: \u001b[1;36m1.\u001b[0m681641GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_solved_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/max_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/min_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_format_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_outcome_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_length_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-06</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_action_entropy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2890625</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_batches_visited'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'train/mean_batch_returns'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_solved_rate'\u001b[0m: \u001b[1;36m0.5\u001b[0m,\n",
       "    \u001b[32m'train/mean_num_words_in_completions'\u001b[0m: \u001b[1;36m14.5\u001b[0m,\n",
       "    \u001b[32m'train/max_num_words_in_completions'\u001b[0m: \u001b[1;36m32.0\u001b[0m,\n",
       "    \u001b[32m'train/min_num_words_in_completions'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_format_returns'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_outcome_returns'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_length_penalty'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/lr'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "    \u001b[32m'train/mean_action_entropy'\u001b[0m: \u001b[1;36m0.2890625\u001b[0m,\n",
       "    \u001b[32m'num_batches_visited'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replay_buffer = trainer.collect_trajectories(\n",
    "    init_train_state, \n",
    "    batch_inputs, \n",
    "    0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = replay_buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = trainer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences -> torch.Size([270])\n",
      "action_log_probs -> torch.Size([269])\n",
      "returns -> torch.Size([])\n",
      "solved_mask -> torch.Size([])\n",
      "advantages -> torch.Size([])\n",
      "attention_mask -> torch.Size([270])\n",
      "action_mask -> torch.Size([269])\n"
     ]
    }
   ],
   "source": [
    "for key in exp.keys:\n",
    "    val = getattr(exp, key)\n",
    "    if val is not None:\n",
    "        print(key, '->', val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Janessa has a plan to give her brother Dexter his first collection of baseball cards. She currently has 4 cards in addition to the 13 that her father gave her.  She ordered a collection of 36 cards from eBay. After inspecting the cards she found 4 cards are in bad shape and decides to throw them away. Janessa ended up giving Dexter 29 cards. How many cards did Janessa keep for herself?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Janessa initially has 4 cards and her father gave her an additional 13 cards, so she now has a total of 4 + 13 = 17 cards.\n",
      "She then ordered a collection of 36 cards from eBay, so she now has a total of 17 + 36 = 53 cards.\n",
      "After inspecting the cards, she found 4 cards in bad shape, so she had 53 - 4 = 49 cards remaining.\n",
      "After giving Dexter 29 cards, she ended up giving him 29 cards, so she kept 49 - 29 = 20 cards for herself.\n",
      "The answer is: $\\boxed{20}$.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(exp.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Janessa has a plan to give her brother Dexter his first collection of baseball cards. She currently has 4 cards in addition to the 13 that her father gave her.  She ordered a collection of 36 cards from eBay. After inspecting the cards she found 4 cards are in bad shape and decides to throw them away. Janessa ended up giving Dexter 29 cards. How many cards did Janessa keep for herself?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Janessa initially has 4 cards and her father gave her an additional 13 cards, so she now has a total of 4 + 13 = 17 cards.\n",
      "She then ordered a collection of 36 cards from eBay, so she now has a total of 17 + 36 = 53 cards.\n",
      "After inspecting the cards, she found 4 cards in bad shape, so she had 53 - 4 = 49 cards remaining.\n",
      "After giving Dexter 29 cards, she ended up giving him 29 cards, so she kept 49 - 29 = 20 cards for herself.\n",
      "The answer is: $\\boxed{20}$.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp.sequences[exp.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.solved_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(0., dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Janessa has a plan to give her brother Dexter his first collection of baseball cards. She currently has 4 cards in addition to the 13 that her father gave her.  She ordered a collection of 36 cards from eBay. After inspecting the cards she found 4 cards are in bad shape and decides to throw them away. Janessa ended up giving Dexter 29 cards. How many cards did Janessa keep for herself?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Janessa initially has 4 cards and her father gave her 13 cards, so she now has 4 + 13 = 17 cards.\n",
      "She then ordered a collection of 36 cards from eBay, so she now has 17 + 36 = 53 cards.\n",
      "After inspecting the cards, she found 4 cards in bad shape and decides to throw them away, so she now has 53 - 4 = 49 cards.\n",
      "She ended up giving Dexter 29 cards, so she kept 49 - 29 = 20 cards for herself.\n",
      "The answer is: $\\boxed{20}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp1 = replay_buffer[1]\n",
    "print(exp1.solved_mask)\n",
    "print(exp1.returns)\n",
    "print(exp1.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp1.sequences[exp1.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(0., dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Janessa has a plan to give her brother Dexter his first collection of baseball cards. She currently has 4 cards in addition to the 13 that her father gave her.  She ordered a collection of 36 cards from eBay. After inspecting the cards she found 4 cards are in bad shape and decides to throw them away. Janessa ended up giving Dexter 29 cards. How many cards did Janessa keep for herself?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Janessa initially has 4 cards and her father gave her 13, so she has a total of 4 + 13 = 17 cards.\n",
      "She then ordered a collection of 36 cards from eBay, so she now has a total of 17 + 36 = 53 cards.\n",
      "After inspecting the cards, she found 4 cards in bad shape and decides to throw them away, so she now has 53 - 4 = 49 cards.\n",
      "Janessa ended up giving Dexter 29 cards, so she kept 49 - 29 = 20 cards for herself.\n",
      "The answer is: $\\boxed{20}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp2 = replay_buffer[2]\n",
    "print(exp2.solved_mask)\n",
    "print(exp2.returns)\n",
    "print(exp2.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp2.sequences[exp2.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.bfloat16)\n",
      "tensor(-1., dtype=torch.bfloat16)\n",
      "tensor(0., dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Quentavious has 5 nickels. His friend offers him some gum and will give him two pieces per nickel. If Quentavious leaves with 2 nickels, how many pieces of gum did he get?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Quentavious starts with 5 nickels, but he leaves with 2 nickels, so he has 5 - 2 = 3 nickels left.\n",
      "His friend gives him 2 pieces of gum per nickel, so he gets 3 x 2 = 6 pieces of gum.\n",
      "The answer is: $\\boxed{6}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp3 = replay_buffer[3]\n",
    "print(exp3.solved_mask)\n",
    "print(exp3.returns)\n",
    "print(exp3.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp3.sequences[exp3.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quentavious starts with 5 nickels, but he leaves with 2 nickels, so he has 5 - 2 = 3 nickels left.\n",
      "His friend gives him 2 pieces of gum per nickel, so he gets 3 x 2 = 6 pieces of gum.\n",
      "The answer is: $\\boxed{6}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp3.sequences[1:][exp3.action_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_sampler = DataLoader(\n",
    "    replay_buffer,\n",
    "    batch_size=trainer.rl_config.mini_batch_size,\n",
    "    shuffle= False,\n",
    "    drop_last=False,\n",
    "    collate_fn=join_experience_batch,\n",
    "    num_workers=trainer.base_config.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_exp = next(iter(experience_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), torch.Size([6]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_exp.returns.shape, next_exp.advantages.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences -> torch.Size([6, 270])\n",
      "action_log_probs -> torch.Size([6, 269])\n",
      "returns -> torch.Size([6])\n",
      "solved_mask -> torch.Size([6])\n",
      "advantages -> torch.Size([6])\n",
      "attention_mask -> torch.Size([6, 270])\n",
      "action_mask -> torch.Size([6, 269])\n"
     ]
    }
   ],
   "source": [
    "for key in next_exp.keys:\n",
    "    val = getattr(next_exp, key)\n",
    "    if val is not None:\n",
    "        print(key, '->', val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_exp = next_exp.to(init_train_state[\"model\"].device) \n",
    "log_probs, _ = sequences_log_probs(\n",
    "    init_train_state[\"model\"], \n",
    "    sequence_ids= next_exp.sequences, \n",
    "    attention_mask= next_exp.attention_mask,\n",
    "    return_entropy=False,\n",
    "    logits_minibatch_size=trainer.rl_config.logits_minibatch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 269])\n"
     ]
    }
   ],
   "source": [
    "print(log_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "loss, mean_kl, mean_actor_loss = trainer.actor_loss(\n",
    "    log_probs=log_probs, \n",
    "    experience= next_exp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<CompiledFunctionBackward>)\n",
      "0\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(mean_kl)\n",
    "print(mean_actor_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
