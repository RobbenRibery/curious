{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "import torch  \n",
    "\n",
    "from curious.utils.utils import move_paddings_to_right\n",
    "from curious.config import TrainingConfig, RLConfig, WandbConfig, BaseConfig, SamplingConfig, RewardConfig, SFLConfig \n",
    "from curious.train.training_setup import set_up_training\n",
    "from curious.train.trainer import PolicyGradientTrainer\n",
    "\n",
    "PAD_TOKEN_ID = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  1,   2,   3, 890, 891, 128, 128],\n",
       "         [  1,   2,   3,   4, 899, 900, 911]]),\n",
       " tensor([[False, False,  True,  True, False, False],\n",
       "         [False, False, False,  True,  True,  True]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 1, 1, 1],\n",
    "        [0, 1, 1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_ids = torch.tensor(\n",
    "    [\n",
    "        [PAD_TOKEN_ID, PAD_TOKEN_ID, 1, 2, 3,],\n",
    "        [PAD_TOKEN_ID, 1,            2, 3, 4,],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sequence_ids = torch.tensor(\n",
    "    [\n",
    "        [PAD_TOKEN_ID, PAD_TOKEN_ID, 1, 2, 3, 890, 891, PAD_TOKEN_ID, PAD_TOKEN_ID, PAD_TOKEN_ID],\n",
    "        [PAD_TOKEN_ID, 1,            2, 3, 4, 899, 900, 911,          PAD_TOKEN_ID, PAD_TOKEN_ID],\n",
    "    ]\n",
    ")\n",
    "\n",
    "move_paddings_to_right(input_ids, attention_mask, sequence_ids, PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Loading target policy Qwen/Qwen2-0.5B-Instruct ####\n",
      "Applied Liger kernels to Qwen2\n",
      "#### Loading dataset openai/gsm8k ####\n",
      "Detected train_max_length: 212\n",
      "Setting train_max_length to 212\n",
      "Detected test_max_length: 188\n",
      "Setting test_max_length to 188\n",
      "#### Loading rollout data loader ####\n",
      "#### Loading KL controller ####\n",
      "#### Loading reference model ####\n",
      "Applied Liger kernels to Qwen2\n",
      "#### Defining actor loss ####\n",
      "#### Defining reward model ####\n",
      "#### Defining generation config ####\n",
      "#### Defining evaluation config ####\n",
      "#### Defining optimizer ####\n",
      "#### Defining lr scheduler ####\n"
     ]
    }
   ],
   "source": [
    "train_config = TrainingConfig(\n",
    "    rl_config=RLConfig(\n",
    "        group_size=3, \n",
    "        mini_batch_size=6,\n",
    "        \n",
    "    ),\n",
    "    wandb_config=WandbConfig(),\n",
    "    base_config=BaseConfig(\n",
    "        train_batch_size=2,\n",
    "        \n",
    "    ),\n",
    "    sampling_config=SamplingConfig(\n",
    "        max_new_tokens=256,\n",
    "    ),\n",
    "    reward_config=RewardConfig(),\n",
    "    sfl_config=SFLConfig(\n",
    "    ),\n",
    ")\n",
    "#train_config.rl_config\n",
    "training_setup, init_train_state = set_up_training(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['run_name', 'device', 'seed', 'model', 'optimizer', 'lr_scheduler', 'reference_model', 'kl_controller'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_train_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PolicyGradientTrainer(training_setup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch \u001b[1;36m0\u001b[0m of \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 436 354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] Graph break from `Tensor.item()`, consider setting:\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] or:\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] to include these operations in the captured graph.\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] \n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] Graph break: from user code at:\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/teamspace/studios/this_studio/curious/curious/sampling/sampling.py\", line 293, in sequences_log_probs\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     mini_output = model(input_ids=mini_ids, attention_mask=mini_mask, use_cache=False)\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     return func(*args, **kwargs)\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/liger_kernel/transformers/model/qwen2.py\", line 188, in lce_forward\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     outputs = self.model(\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     output = func(self, *args, **kwargs)\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 519, in forward\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     causal_mask = self._update_causal_mask(\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]   File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 596, in _update_causal_mask\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0]     if attention_mask is not None and 0.0 in attention_mask:\n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] \n",
      "W0510 15:30:16.691000 279638 /system/conda/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/tensor.py:869] [1/0] \n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:679: UserWarning: Graph break due to unsupported builtin gc.collect. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.\n",
      "  torch._dynamo.utils.warn_once(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Batch indx <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Batch indx \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.memory_allocated: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>872596GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.memory_allocated: \u001b[1;36m1.\u001b[0m872596GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.memory_reserved: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>974609GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.memory_reserved: \u001b[1;36m2.\u001b[0m974609GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.cuda.max_memory_reserved: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.</span>009766GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.cuda.max_memory_reserved: \u001b[1;36m3.\u001b[0m009766GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.416015625</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_solved_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1669921875</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/max_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/min_num_words_in_completions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_format_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_outcome_returns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4166666666666667</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_batch_length_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-06</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train/mean_action_entropy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.28125</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_batches_visited'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'train/mean_batch_returns'\u001b[0m: \u001b[1;36m-0.416015625\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_solved_rate'\u001b[0m: \u001b[1;36m0.1669921875\u001b[0m,\n",
       "    \u001b[32m'train/mean_num_words_in_completions'\u001b[0m: \u001b[1;36m38.0\u001b[0m,\n",
       "    \u001b[32m'train/max_num_words_in_completions'\u001b[0m: \u001b[1;36m82.0\u001b[0m,\n",
       "    \u001b[32m'train/min_num_words_in_completions'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_format_returns'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_outcome_returns'\u001b[0m: \u001b[1;36m-0.4166666666666667\u001b[0m,\n",
       "    \u001b[32m'train/mean_batch_length_penalty'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'train/lr'\u001b[0m: \u001b[1;36m1e-06\u001b[0m,\n",
       "    \u001b[32m'train/mean_action_entropy'\u001b[0m: \u001b[1;36m0.28125\u001b[0m,\n",
       "    \u001b[32m'num_batches_visited'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next_state, next_replay_buffer = trainer.train(init_train_state)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = next_replay_buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = trainer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences\n",
      "torch.Size([354])\n",
      "action_log_probs\n",
      "torch.Size([353])\n",
      "log_probs_ref\n",
      "torch.Size([353])\n",
      "returns\n",
      "torch.Size([])\n",
      "solved_mask\n",
      "torch.Size([])\n",
      "advantages\n",
      "torch.Size([])\n",
      "attention_mask\n",
      "torch.Size([354])\n",
      "action_mask\n",
      "torch.Size([353])\n"
     ]
    }
   ],
   "source": [
    "for key in exp.keys:\n",
    "    val = getattr(exp, key)\n",
    "    if val is not None:\n",
    "        print(key)\n",
    "        print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Elizabeth has 20 dollars and wants to buy pens and pencils. Each pencil costs $1.60 and each pen cost 2 dollars. How many pencils can she buy with her 20 dollars if she wants 6 pens?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Elizabeth wants to buy 6 pens, so she has 6 * $2 = $12 to spend.\n",
      "She has $20 and she has $12 to spend, so she can buy $20 - $12 = $8 more pencils.\n",
      "Each pencil costs $1.60, so with $8, she can buy $8 / $1.60 = 5 pencils.\n",
      "The answer is: $\\boxed{5}$<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(exp.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Elizabeth has 20 dollars and wants to buy pens and pencils. Each pencil costs $1.60 and each pen cost 2 dollars. How many pencils can she buy with her 20 dollars if she wants 6 pens?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Elizabeth wants to buy 6 pens, so she has 6 * $2 = $12 to spend.\n",
      "She has $20 and she has $12 to spend, so she can buy $20 - $12 = $8 more pencils.\n",
      "Each pencil costs $1.60, so with $8, she can buy $8 / $1.60 = 5 pencils.\n",
      "The answer is: $\\boxed{5}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp.sequences[exp.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.solved_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5781, dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(exp.advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(1., dtype=torch.bfloat16)\n",
      "tensor(1.1562, dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Elizabeth has 20 dollars and wants to buy pens and pencils. Each pencil costs $1.60 and each pen cost 2 dollars. How many pencils can she buy with her 20 dollars if she wants 6 pens?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Elizabeth wants to buy 6 pens, and each pen costs 2 dollars, so the total cost of the pens is 6 * 2 = 12 dollars.\n",
      "Elizabeth has 20 dollars in total, and she wants to buy 12 dollars worth of pens. This means she has 20 - 12 = 8 dollars left to spend on pencils.\n",
      "Each pencil costs 1.60 dollars, so to find out how many pencils she can buy with the remaining money, we divide the remaining money by the cost of each pencil: 8 / 1.60 = 5.\n",
      "So, Elizabeth can buy 5 pencils with her remaining 8 dollars.\n",
      "The answer is: $\\boxed{5}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp1 = next_replay_buffer[1]\n",
    "print(exp1.solved_mask)\n",
    "print(exp1.returns)\n",
    "print(exp1.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp1.sequences[exp1.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.bfloat16)\n",
      "tensor(-1., dtype=torch.bfloat16)\n",
      "tensor(-0.5781, dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Elizabeth has 20 dollars and wants to buy pens and pencils. Each pencil costs $1.60 and each pen cost 2 dollars. How many pencils can she buy with her 20 dollars if she wants 6 pens?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " Elizabeth wants to buy 6 pens, and each pen costs 2 dollars, so the total cost of the pens is 6 * 2 = 12 dollars.\n",
      "Elizabeth has 20 dollars in total, so she can spend 20 - 12 = 8 dollars on pencils.\n",
      "Each pencil costs 1.60 dollars, so to find out how many pencils she can buy, we divide the amount of money she has left by the cost of each pencil: 8 / 1.60 = 5.\n",
      "Elizabeth can buy 5 pencils with her 20 dollars.\n",
      "The answer is: $\\boxed{5}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp2 = next_replay_buffer[2]\n",
    "print(exp2.solved_mask)\n",
    "print(exp2.returns)\n",
    "print(exp2.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp2.sequences[exp2.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.bfloat16)\n",
      "tensor(-0.5000, dtype=torch.bfloat16)\n",
      "tensor(0., dtype=torch.bfloat16)\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within $\\boxed{}$.<|im_end|>\n",
      "<|im_start|>user\n",
      "Billy and Tiffany are having a contest to see how can run the most miles in a week. On Sunday, Monday, and Tuesday, Billy runs 1 mile each day and Tiffany runs 2 miles each day. On Wednesday, Thursday, and Friday, Billy runs 1 mile each day and Tiffany runs a 1/3 of a mile each day. On Saturday Tiffany assumes she's going to win and takes the day off. How many miles does Billy have to run on Saturday to tie Tiffany?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " On Sunday, Monday, and Tuesday, Billy runs 1 mile each day, so he runs a total of 1+1+1 = 3 miles.\n",
      "On Wednesday, Thursday, and Friday, Billy runs 1 mile each day, so he runs a total of 1+1+1 = 3 miles.\n",
      "On Saturday, Tiffany takes the day off, so she doesn't run any miles.\n",
      "Tiffany runs a 1/3 of a mile each day from Sunday to Friday, so she runs 1/3*5 = 1.67 miles in total.\n",
      "Tiffany runs 1.67 miles in a week, and Billy runs 3 miles, so Billy needs to run 3-1.67 = 1.33 miles on Saturday to tie Tiffany.\n",
      "However, Billy can only run whole miles, so he needs to run an additional 1 mile on Saturday.\n",
      "Billy needs to run 1.33+1 = 2.33 miles on Saturday to tie Tiffany.\n",
      "The answer is: $\\boxed{2.33}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "exp3 = next_replay_buffer[3]\n",
    "print(exp3.solved_mask)\n",
    "print(exp3.returns)\n",
    "print(exp3.advantages)\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp3.sequences[exp3.attention_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " On Sunday, Monday, and Tuesday, Billy runs 1 mile each day, so he runs a total of 1+1+1 = 3 miles.\n",
      "On Wednesday, Thursday, and Friday, Billy runs 1 mile each day, so he runs a total of 1+1+1 = 3 miles.\n",
      "On Saturday, Tiffany takes the day off, so she doesn't run any miles.\n",
      "Tiffany runs a 1/3 of a mile each day from Sunday to Friday, so she runs 1/3*5 = 1.67 miles in total.\n",
      "Tiffany runs 1.67 miles in a week, and Billy runs 3 miles, so Billy needs to run 3-1.67 = 1.33 miles on Saturday to tie Tiffany.\n",
      "However, Billy can only run whole miles, so he needs to run an additional 1 mile on Saturday.\n",
      "Billy needs to run 1.33+1 = 2.33 miles on Saturday to tie Tiffany.\n",
      "The answer is: $\\boxed{2.33}$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(\n",
    "        exp3.sequences[1:][exp3.action_mask]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
